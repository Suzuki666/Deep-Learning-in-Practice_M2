{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "674e1a2190404332bb66e1c8000b88a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb4eedcec5a94189b8f7c5a1d1d954b2",
              "IPY_MODEL_f93eec4ec41b469587108360446ae8a2",
              "IPY_MODEL_fd55ca24d7364a3d9ab4cdc12cf157e4"
            ],
            "layout": "IPY_MODEL_2658dba4803740889cf89fc423f5050e"
          }
        },
        "fb4eedcec5a94189b8f7c5a1d1d954b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d963bbf55022475295a0663fa781eaa7",
            "placeholder": "​",
            "style": "IPY_MODEL_84784358c0ff4965a7b0b8ba530ebc52",
            "value": "README.md: 100%"
          }
        },
        "f93eec4ec41b469587108360446ae8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9f6255e9b849498e4598399899f01e",
            "max": 1061,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd62641b7d6541b0add7741b742e4105",
            "value": 1061
          }
        },
        "fd55ca24d7364a3d9ab4cdc12cf157e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aac6397929d14b80971ab09eff52cd08",
            "placeholder": "​",
            "style": "IPY_MODEL_6088a18a8c8e4bbd8fdaa0f922658526",
            "value": " 1.06k/1.06k [00:00&lt;00:00, 110kB/s]"
          }
        },
        "2658dba4803740889cf89fc423f5050e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d963bbf55022475295a0663fa781eaa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84784358c0ff4965a7b0b8ba530ebc52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9f6255e9b849498e4598399899f01e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd62641b7d6541b0add7741b742e4105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aac6397929d14b80971ab09eff52cd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6088a18a8c8e4bbd8fdaa0f922658526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e418e240318491a8be58598ba9f2986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7df7ffbc29714d4d8e28f89d52844c8c",
              "IPY_MODEL_75d49d1816d64e23934131989bd7f9ed",
              "IPY_MODEL_577b165d0d3d49e6b56883cf490bdbba"
            ],
            "layout": "IPY_MODEL_2eb35e602d3b40a791ca1b1285b7f802"
          }
        },
        "7df7ffbc29714d4d8e28f89d52844c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2eed82a79c48afa8d4972bd26d82d5",
            "placeholder": "​",
            "style": "IPY_MODEL_33244d60841f4ac58707759117ff0450",
            "value": "(…)-00000-of-00004-2d5a1467fff1081b.parquet: 100%"
          }
        },
        "75d49d1816d64e23934131989bd7f9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f1838c11204d5bb11a516a2356a25c",
            "max": 248731111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9435a59d307942f29084292695e246e8",
            "value": 248731111
          }
        },
        "577b165d0d3d49e6b56883cf490bdbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70eea11972fc4432b02e19f157f70a9a",
            "placeholder": "​",
            "style": "IPY_MODEL_4400ca0e9c4b408e9e8c9dcc35d1f932",
            "value": " 249M/249M [00:01&lt;00:00, 246MB/s]"
          }
        },
        "2eb35e602d3b40a791ca1b1285b7f802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe2eed82a79c48afa8d4972bd26d82d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33244d60841f4ac58707759117ff0450": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3f1838c11204d5bb11a516a2356a25c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9435a59d307942f29084292695e246e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70eea11972fc4432b02e19f157f70a9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4400ca0e9c4b408e9e8c9dcc35d1f932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab0d6dca72304ec58387698586aab54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49dc69cc312c4146aabf049fb3c15c9c",
              "IPY_MODEL_caae2e9517b04fa7adfdb50c9f209271",
              "IPY_MODEL_e9af8d6f73854ca1a65b22505870d0c5"
            ],
            "layout": "IPY_MODEL_88882eeab19442e69e0a7d280992369c"
          }
        },
        "49dc69cc312c4146aabf049fb3c15c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77660fb83f344710aa0080351eaef0f3",
            "placeholder": "​",
            "style": "IPY_MODEL_bd68853fe6cd49028968f2fc14fa80b3",
            "value": "(…)-00001-of-00004-5852b56a2bd28fd9.parquet: 100%"
          }
        },
        "caae2e9517b04fa7adfdb50c9f209271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_952de0c226ea455d921eedbfa30fdfb7",
            "max": 248171980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3fa807af904422c82f158ccc58eed22",
            "value": 248171980
          }
        },
        "e9af8d6f73854ca1a65b22505870d0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67f05cf36c6a4a6d8314c9588544184b",
            "placeholder": "​",
            "style": "IPY_MODEL_0288c67205fb4fcc9e705351c818b3cf",
            "value": " 248M/248M [00:01&lt;00:00, 247MB/s]"
          }
        },
        "88882eeab19442e69e0a7d280992369c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77660fb83f344710aa0080351eaef0f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd68853fe6cd49028968f2fc14fa80b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "952de0c226ea455d921eedbfa30fdfb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3fa807af904422c82f158ccc58eed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67f05cf36c6a4a6d8314c9588544184b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0288c67205fb4fcc9e705351c818b3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42fb9f59cfc44b58898dcc611b3d1732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dba3a2d56c5340c08aad3b65288871cd",
              "IPY_MODEL_64680949efb04462978cd2e7ee588fc8",
              "IPY_MODEL_0e6d0a7073144a319a5f55ed460ef26b"
            ],
            "layout": "IPY_MODEL_3f0ea25502bd46c3b9d08670437af379"
          }
        },
        "dba3a2d56c5340c08aad3b65288871cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5a7697a86740eaa608765380a818ea",
            "placeholder": "​",
            "style": "IPY_MODEL_eb3c4ede4a1d450b8e7167ae610da4fb",
            "value": "(…)-00002-of-00004-a26307300439e943.parquet: 100%"
          }
        },
        "64680949efb04462978cd2e7ee588fc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33bf1175f4d2497aa8128bf54edc4421",
            "max": 245894874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f22267bf265644b5ad94112fba555e5c",
            "value": 245894874
          }
        },
        "0e6d0a7073144a319a5f55ed460ef26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b79cecccbf4af49e808b3939b1001f",
            "placeholder": "​",
            "style": "IPY_MODEL_cd2b1e70e903465cbb03681af1df2848",
            "value": " 246M/246M [00:00&lt;00:00, 247MB/s]"
          }
        },
        "3f0ea25502bd46c3b9d08670437af379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5a7697a86740eaa608765380a818ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb3c4ede4a1d450b8e7167ae610da4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33bf1175f4d2497aa8128bf54edc4421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22267bf265644b5ad94112fba555e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2b79cecccbf4af49e808b3939b1001f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd2b1e70e903465cbb03681af1df2848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5976942dae8b42b9b18009e7c9645d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7106c3a4ff8d435e8db5413f5fe7afc5",
              "IPY_MODEL_47fa711b2edd43bebf221ddd9cd892f9",
              "IPY_MODEL_471c42b5b5d8408780a1853f2ecf9a39"
            ],
            "layout": "IPY_MODEL_127a027a79f6446d8eb4cfc2921ba049"
          }
        },
        "7106c3a4ff8d435e8db5413f5fe7afc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96adaacdaca4567b0ceab8493b3fb5b",
            "placeholder": "​",
            "style": "IPY_MODEL_e633eaa08a1c416d8ced3562c3a58000",
            "value": "(…)-00003-of-00004-d243063613e5a057.parquet: 100%"
          }
        },
        "47fa711b2edd43bebf221ddd9cd892f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6514ae7c1b1647a2aafb7a687bf20bda",
            "max": 247988350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21e7fcb0f5dd4e5c9a4c4b5edb608232",
            "value": 247988350
          }
        },
        "471c42b5b5d8408780a1853f2ecf9a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1dfd27366f4794b8ef4653cbdcf115",
            "placeholder": "​",
            "style": "IPY_MODEL_788d1485dd0040c79ac28eb3b9e5df24",
            "value": " 248M/248M [00:01&lt;00:00, 249MB/s]"
          }
        },
        "127a027a79f6446d8eb4cfc2921ba049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96adaacdaca4567b0ceab8493b3fb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e633eaa08a1c416d8ced3562c3a58000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6514ae7c1b1647a2aafb7a687bf20bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e7fcb0f5dd4e5c9a4c4b5edb608232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1dfd27366f4794b8ef4653cbdcf115": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788d1485dd0040c79ac28eb3b9e5df24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ba244a05ea44bda3d6421701b7f324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c39e58d6d3c42709b16b12b918b8c48",
              "IPY_MODEL_08175fab5a744f38965029d445e965ad",
              "IPY_MODEL_e846e384ab9e4068ba6281254997ccaa"
            ],
            "layout": "IPY_MODEL_c7c97c88b9e74e4c9500eea796fec8ac"
          }
        },
        "9c39e58d6d3c42709b16b12b918b8c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c1b54611ba424ea7cecbe10ad18aec",
            "placeholder": "​",
            "style": "IPY_MODEL_7760ecb175a44ecb94b73b1886ba956b",
            "value": "(…)-00000-of-00001-869c898b519ad725.parquet: 100%"
          }
        },
        "08175fab5a744f38965029d445e965ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ca02a43dd145a5b957572221d68d77",
            "max": 9989127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9968eb3a10a94c589069da585a4c30a8",
            "value": 9989127
          }
        },
        "e846e384ab9e4068ba6281254997ccaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa016628ce1642e3b2fac20ecd21fb61",
            "placeholder": "​",
            "style": "IPY_MODEL_3b437a10911f4d0dac819d740b2b705f",
            "value": " 9.99M/9.99M [00:00&lt;00:00, 193MB/s]"
          }
        },
        "c7c97c88b9e74e4c9500eea796fec8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c1b54611ba424ea7cecbe10ad18aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7760ecb175a44ecb94b73b1886ba956b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77ca02a43dd145a5b957572221d68d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9968eb3a10a94c589069da585a4c30a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa016628ce1642e3b2fac20ecd21fb61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b437a10911f4d0dac819d740b2b705f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9afe22b4e97a4db385b95dde83901efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ef29e0e250547278ade74a7ed1a0282",
              "IPY_MODEL_c321a8aa081c4fe0af8c295bfdfeaf39",
              "IPY_MODEL_1bf4c09b4c914508ac0c68c00a6eb72e"
            ],
            "layout": "IPY_MODEL_9e291f7017274c57ad0bf7248ae67ab2"
          }
        },
        "6ef29e0e250547278ade74a7ed1a0282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31e5c68e28eb4a7dae8d30e299fab4c4",
            "placeholder": "​",
            "style": "IPY_MODEL_d4ef9c6eed814f5fa2f6af28f111df52",
            "value": "Generating train split: 100%"
          }
        },
        "c321a8aa081c4fe0af8c295bfdfeaf39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6361063949014595949c9817b7eb9170",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_924b8fe1e94c452a8dc65f4962ea2bed",
            "value": 2119719
          }
        },
        "1bf4c09b4c914508ac0c68c00a6eb72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdfe897cda5f4722b364efe7dee68999",
            "placeholder": "​",
            "style": "IPY_MODEL_6b1139c1bd58491a9629ef3529da1bd8",
            "value": " 2119719/2119719 [00:06&lt;00:00, 306922.41 examples/s]"
          }
        },
        "9e291f7017274c57ad0bf7248ae67ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31e5c68e28eb4a7dae8d30e299fab4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4ef9c6eed814f5fa2f6af28f111df52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6361063949014595949c9817b7eb9170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "924b8fe1e94c452a8dc65f4962ea2bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdfe897cda5f4722b364efe7dee68999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1139c1bd58491a9629ef3529da1bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "567d5d0103aa4b3cbb36ba6d06517eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd56968658004449a8fa7c331646142e",
              "IPY_MODEL_4ab48db2aba74d3abb636661110727c7",
              "IPY_MODEL_d270e031b68747fbad6afe4770021653"
            ],
            "layout": "IPY_MODEL_3eda89e8f6784a8a97647941a5343e26"
          }
        },
        "bd56968658004449a8fa7c331646142e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce9fa4607012457396a246c8f4571f44",
            "placeholder": "​",
            "style": "IPY_MODEL_60201c68f3eb4998957fcffec3d06385",
            "value": "Generating validation split: 100%"
          }
        },
        "4ab48db2aba74d3abb636661110727c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04f0be84e2b45aab4f20a05cc4c7b91",
            "max": 21990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c4b083a4ba4412089799d70797d4576",
            "value": 21990
          }
        },
        "d270e031b68747fbad6afe4770021653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1091ac7ff713420c9e21a1c1f01b5d0a",
            "placeholder": "​",
            "style": "IPY_MODEL_e132eb7bca4f461daf6963d86f06af58",
            "value": " 21990/21990 [00:00&lt;00:00, 261500.36 examples/s]"
          }
        },
        "3eda89e8f6784a8a97647941a5343e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9fa4607012457396a246c8f4571f44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60201c68f3eb4998957fcffec3d06385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a04f0be84e2b45aab4f20a05cc4c7b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c4b083a4ba4412089799d70797d4576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1091ac7ff713420c9e21a1c1f01b5d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e132eb7bca4f461daf6963d86f06af58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\" style=\"color:green;font-size: 3em;\">Homework 1:\n",
        "Implementing Transformers From Scratch Using PyTorch</h1>\n",
        "\n",
        "\n",
        "# Part 1: Introduction\n",
        "\n",
        "In this homework, you will implement the transformer architecture as described in the \"Attention is All You Need\" paper from scratch using PyTorch.\n",
        "\n",
        "**Instructions:**\n",
        "- Follow the notebook sections to implement various components of the transformer.\n",
        "- Code cells marked with `TODO` are parts that you need to complete.\n",
        "- Ensure your code runs correctly by the end of the notebook.\n"
      ],
      "metadata": {
        "id": "xm360WahqHQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Import Libraries"
      ],
      "metadata": {
        "id": "Qe47nb3t5mKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required libraries\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math,copy,re\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "warnings.simplefilter(\"ignore\")\n",
        "print(torch.__version__)\n",
        "\n",
        "\n",
        "# Set the seed value\n",
        "seed_value = 0\n",
        "\n",
        "# For CPU\n",
        "torch.manual_seed(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# For GPU (if using CUDA)\n",
        "print(\"I cuda available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-20T09:58:01.799443Z",
          "iopub.execute_input": "2022-09-20T09:58:01.799872Z",
          "iopub.status.idle": "2022-09-20T09:58:01.806881Z",
          "shell.execute_reply.started": "2022-09-20T09:58:01.79983Z",
          "shell.execute_reply": "2022-09-20T09:58:01.805902Z"
        },
        "trusted": true,
        "id": "eS5YPNAHqHQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94e4ec0-5471-4b8c-8e70-00ad3e258f0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu124\n",
            "I cuda available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before diving into the decoder, let us discuss some of its components.\n",
        "\n",
        "\n",
        "# Part 3: Basic Transformer Class\n",
        "\n",
        "Neural networks operate over numerical weights and biases but natural language does not naturally take this form. Thus first, we need to convert an input sequence into an embedding vector. Embedding vectors create a more semantic representation of each token.\n"
      ],
      "metadata": {
        "id": "Oz-3i3rXqHQP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1: Embeddings Matrix\n",
        "\n",
        "\n",
        "**3.1: Understanding Embeddings**\n",
        "\n",
        "Transformers require numerical input, but natural language consists of words. To convert words into a numerical format, we use embeddings, which map each word to a high-dimensional vector. These vectors capture semantic information about the words.\n",
        "\n",
        "**Task:**\n",
        "\n",
        "- Instantiate an embedding layer using the `nn.Embedding` class in PyTorch.\n",
        "- Investigate the properties of the embedding matrix.\n",
        "- Embed multiple tokens and analyze the results.\n",
        "\n",
        "**Step-by-Step Instructions:**\n",
        "\n",
        "1. **Create an Embedding Layer:**\n",
        "    - Assume a vocabulary size of 100 and an embedding dimension of 512.\n",
        "    - Create an embedding layer using `nn.Embedding`.\n",
        "\n",
        "2. **Analyze the Embedding Matrix:**\n",
        "    - Print the shape of the embedding matrix.\n",
        "    - Extract and print the first 3 rows of the embedding matrix (corresponding to tokens 0, 1, and 2).\n",
        "  \n",
        "3. **Embed Multiple Tokens:**\n",
        "    - Create an input tensor representing a sequence of tokens. For example, use the tokens `[0, 1, 2]`.\n",
        "    - Pass this input through the embedding layer.\n",
        "    - Print and compare the embedding vectors for tokens 0, 1, and 2 with the first 3 rows of the embedding matrix.\n"
      ],
      "metadata": {
        "id": "FXCj2-FTumRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create an Embedding Layer\n",
        "vocabulary_size = 100\n",
        "embedding_dimension = 512\n",
        "embedding_layer = nn.Embedding(vocabulary_size, embedding_dimension)\n",
        "\n",
        "print(\"Embedding Layer:\", embedding_layer)\n",
        "\n",
        "# TODO: Print the shape of the embedding matrix\n",
        "# TODO: Analyze the Embedding Matrix\n",
        "embedding_matrix = embedding_layer.weight\n",
        "print(f\"Shape of Embedding Matrix:{embedding_matrix.shape}\")\n",
        "\n",
        "# TODO: Print first 3 rows of embedding matrix\n",
        "first_three_rows = embedding_matrix[:3]\n",
        "print(\"First 3 Rows of Embedding Matrix:\")\n",
        "print(first_three_rows)\n",
        "\n",
        "# TODO: Embed Multiple Tokens\n",
        "input_tokens = torch.tensor([0, 1, 2])  # Example input tokens\n",
        "embedded_tokens = embedding_layer(input_tokens)\n",
        "\n",
        "print(\"\\n Print embedding Vectors for Tokens 0, 1, 2:\")\n",
        "print(embedded_tokens)\n",
        "\n",
        "# Compare with the first 3 rows of the embedding matrix\n",
        "print(\"\\nCompare with the first 3 rows of the embedding matrix:\")\n",
        "print(torch.allclose(embedded_tokens, first_three_rows, atol=1e-6))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-20T09:58:01.812435Z",
          "iopub.execute_input": "2022-09-20T09:58:01.813133Z",
          "iopub.status.idle": "2022-09-20T09:58:01.820092Z",
          "shell.execute_reply.started": "2022-09-20T09:58:01.813091Z",
          "shell.execute_reply": "2022-09-20T09:58:01.819233Z"
        },
        "trusted": true,
        "id": "oIfO7V3FqHQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a7ece9-cf30-4080-a7dc-096e60531a19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Layer: Embedding(100, 512)\n",
            "Shape of Embedding Matrix:torch.Size([100, 512])\n",
            "First 3 Rows of Embedding Matrix:\n",
            "tensor([[-1.1258, -1.1524, -0.2506,  ..., -1.6989,  1.3094, -1.6613],\n",
            "        [-0.5461, -0.6302, -0.6347,  ...,  0.5374,  1.0826, -1.7105],\n",
            "        [-1.0841, -0.1287, -0.6811,  ..., -0.0363,  0.0981,  0.9636]],\n",
            "       grad_fn=<SliceBackward0>)\n",
            "\n",
            " Print embedding Vectors for Tokens 0, 1, 2:\n",
            "tensor([[-1.1258, -1.1524, -0.2506,  ..., -1.6989,  1.3094, -1.6613],\n",
            "        [-0.5461, -0.6302, -0.6347,  ...,  0.5374,  1.0826, -1.7105],\n",
            "        [-1.0841, -0.1287, -0.6811,  ..., -0.0363,  0.0981,  0.9636]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Compare with the first 3 rows of the embedding matrix:\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2: Positional Encoding\n",
        "\n",
        "The next step is to generate positional encoding. For the model to understand a sentence, it helps to know two things about each token:\n",
        "- What does the token mean semantically?\n",
        "- What is the position of the token in the sentence?\n",
        "\n",
        "In the \"Attention is All You Need\" paper, the authors used the following functions to create positional encoding. A cosine function is used for odd time steps, and a sine function is used for even time steps.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/524/1*yWGV9ck-0ltfV2wscUeo7Q.png\">\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/564/1*SgNlyFaHH8ljBbpCupDhSQ.png\">\n",
        "\n",
        "```\n",
        "pos -> refers to order in the sentence\n",
        "i -> refers to position along embedding vector dimension`\n",
        "```\n",
        "\n",
        "Positional encoding will generate a matrix similar to the embedding matrix. It will create a matrix of dimension sequence length x embedding dimension. For each token (word) in the sequence, we will find the embedding vector, which is of dimension (1, 512), and add it with the corresponding positional vector, which is also of dimension (1, 512), to get a (1, 512) dimension output for each word/token.\n",
        "\n",
        "For example, if we have a batch size of 32 and a sequence length of 10 with an embedding dimension of 512, we will have an embedding vector of dimension (32, 10, 512). Similarly, we will have a positional encoding vector of dimension (32, 10, 512). Then we add both.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/906/1*B-VR6R5vJl3Y7jbMNf5Fpw.png\">\n",
        "\n",
        "<hr>\n",
        "<h3>Task:</h3>\n",
        "Implement the `PositionalEmbedding` class. Complete the `__init__` method to initialize the positional encoding matrix and the `forward` method to add positional encoding to the input embeddings.\n",
        "\n",
        "```\n",
        "Code Hint:\n",
        "Use math.sin and math.cos functions to create the positional encoding matrix.\n",
        "```\n",
        "```\n",
        "Code Hint:\n",
        "Use the nn.Parameter to store the positional encoding matrix.\n",
        "```\n",
        "**Note:** Ensure that the positional encoding matrix is not trained by the optimizer:\n",
        "```\n",
        "Code Hint:\n",
        "This means that the positional encoding matrix do not require gradients. Look at pytorch nn.Parameter for more information.\n",
        "```"
      ],
      "metadata": {
        "id": "6r0XUWTgqHQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, max_seq_len, embed_model_dim):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_seq_len: maximum length of input sequence\n",
        "            embed_model_dim: dimension of embeddings\n",
        "        \"\"\"\n",
        "        super(PositionalEmbedding, self).__init__()\n",
        "        self.embed_dim = embed_model_dim\n",
        "        print(\"Max_seq_len:\", max_seq_len)\n",
        "\n",
        "        # TODO: Initialize the positional encoding matrix using the above\n",
        "        # Shape: (max_seq_len, embed_model_dim)\n",
        "        # Create a positional encoding matrix\n",
        "        position_encoding = torch.zeros(max_seq_len, embed_model_dim)\n",
        "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, embed_model_dim, 2).float() * (-math.log(10000.0) / embed_model_dim))\n",
        "\n",
        "        # Compute sine and cosine for each position\n",
        "        position_encoding[:, 0::2] = torch.sin(position * div_term)\n",
        "        position_encoding[:, 1::2] = torch.cos(position * div_term)\n",
        "        # Store the positional encoding matrix as an nn.Parameter but set requires_grad=False\n",
        "        self.positional_encoding = nn.Parameter(position_encoding, requires_grad=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input vector\n",
        "        Returns:\n",
        "            x: output vector with positional encoding added\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Add positional encoding to the input embeddings\n",
        "        x = x + self.positional_encoding[: x.size(1), :].unsqueeze(0)\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-20T09:58:01.82231Z",
          "iopub.execute_input": "2022-09-20T09:58:01.822658Z",
          "iopub.status.idle": "2022-09-20T09:58:01.833573Z",
          "shell.execute_reply.started": "2022-09-20T09:58:01.822609Z",
          "shell.execute_reply": "2022-09-20T09:58:01.832711Z"
        },
        "trusted": true,
        "id": "z15QUz8yqHQQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the PositionalEmbedding\n",
        "max_seq_len = 10  # Maximum sequence length\n",
        "embed_model_dim = 16  # Dimension of embeddings\n",
        "positional_embedding = PositionalEmbedding(max_seq_len, embed_model_dim)\n",
        "positional_embedding.eval()\n",
        "with torch.no_grad():\n",
        "  batch_size = 2\n",
        "  sequence_length = 10\n",
        "  sample_data = torch.zeros(batch_size, sequence_length, embed_model_dim)\n",
        "\n",
        "  # Pass the sample data through the PositionalEmbedding layer\n",
        "  output = positional_embedding(sample_data)\n",
        "\n",
        "  print(\"Sample Input Data:\")\n",
        "  print(sample_data)\n",
        "  print(\"Output Data with Positional Encoding:\")\n",
        "  print(output)"
      ],
      "metadata": {
        "id": "hokg3w0tJvDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36aa835-2604-4e64-dbe2-a5f9d2bf4479"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max_seq_len: 10\n",
            "Sample Input Data:\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n",
            "Output Data with Positional Encoding:\n",
            "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  3.1098e-01,  9.5042e-01,  9.9833e-02,\n",
            "           9.9500e-01,  3.1618e-02,  9.9950e-01,  9.9998e-03,  9.9995e-01,\n",
            "           3.1623e-03,  9.9999e-01,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
            "           1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  5.9113e-01,  8.0658e-01,  1.9867e-01,\n",
            "           9.8007e-01,  6.3203e-02,  9.9800e-01,  1.9999e-02,  9.9980e-01,\n",
            "           6.3245e-03,  9.9998e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
            "           1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  8.1265e-01,  5.8275e-01,  2.9552e-01,\n",
            "           9.5534e-01,  9.4726e-02,  9.9550e-01,  2.9995e-02,  9.9955e-01,\n",
            "           9.4867e-03,  9.9995e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
            "           1.0000e+00],\n",
            "         [-7.5680e-01, -6.5364e-01,  9.5358e-01,  3.0114e-01,  3.8942e-01,\n",
            "           9.2106e-01,  1.2615e-01,  9.9201e-01,  3.9989e-02,  9.9920e-01,\n",
            "           1.2649e-02,  9.9992e-01,  4.0000e-03,  9.9999e-01,  1.2649e-03,\n",
            "           1.0000e+00],\n",
            "         [-9.5892e-01,  2.8366e-01,  9.9995e-01, -1.0342e-02,  4.7943e-01,\n",
            "           8.7758e-01,  1.5746e-01,  9.8753e-01,  4.9979e-02,  9.9875e-01,\n",
            "           1.5811e-02,  9.9988e-01,  5.0000e-03,  9.9999e-01,  1.5811e-03,\n",
            "           1.0000e+00],\n",
            "         [-2.7942e-01,  9.6017e-01,  9.4715e-01, -3.2080e-01,  5.6464e-01,\n",
            "           8.2534e-01,  1.8860e-01,  9.8205e-01,  5.9964e-02,  9.9820e-01,\n",
            "           1.8973e-02,  9.9982e-01,  6.0000e-03,  9.9998e-01,  1.8974e-03,\n",
            "           1.0000e+00],\n",
            "         [ 6.5699e-01,  7.5390e-01,  8.0042e-01, -5.9944e-01,  6.4422e-01,\n",
            "           7.6484e-01,  2.1956e-01,  9.7560e-01,  6.9943e-02,  9.9755e-01,\n",
            "           2.2134e-02,  9.9976e-01,  6.9999e-03,  9.9998e-01,  2.2136e-03,\n",
            "           1.0000e+00],\n",
            "         [ 9.8936e-01, -1.4550e-01,  5.7432e-01, -8.1863e-01,  7.1736e-01,\n",
            "           6.9671e-01,  2.5029e-01,  9.6817e-01,  7.9915e-02,  9.9680e-01,\n",
            "           2.5296e-02,  9.9968e-01,  7.9999e-03,  9.9997e-01,  2.5298e-03,\n",
            "           1.0000e+00],\n",
            "         [ 4.1212e-01, -9.1113e-01,  2.9126e-01, -9.5664e-01,  7.8333e-01,\n",
            "           6.2161e-01,  2.8078e-01,  9.5977e-01,  8.9879e-02,  9.9595e-01,\n",
            "           2.8457e-02,  9.9960e-01,  8.9999e-03,  9.9996e-01,  2.8460e-03,\n",
            "           1.0000e+00]],\n",
            "\n",
            "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
            "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "           1.0000e+00],\n",
            "         [ 8.4147e-01,  5.4030e-01,  3.1098e-01,  9.5042e-01,  9.9833e-02,\n",
            "           9.9500e-01,  3.1618e-02,  9.9950e-01,  9.9998e-03,  9.9995e-01,\n",
            "           3.1623e-03,  9.9999e-01,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
            "           1.0000e+00],\n",
            "         [ 9.0930e-01, -4.1615e-01,  5.9113e-01,  8.0658e-01,  1.9867e-01,\n",
            "           9.8007e-01,  6.3203e-02,  9.9800e-01,  1.9999e-02,  9.9980e-01,\n",
            "           6.3245e-03,  9.9998e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
            "           1.0000e+00],\n",
            "         [ 1.4112e-01, -9.8999e-01,  8.1265e-01,  5.8275e-01,  2.9552e-01,\n",
            "           9.5534e-01,  9.4726e-02,  9.9550e-01,  2.9995e-02,  9.9955e-01,\n",
            "           9.4867e-03,  9.9995e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
            "           1.0000e+00],\n",
            "         [-7.5680e-01, -6.5364e-01,  9.5358e-01,  3.0114e-01,  3.8942e-01,\n",
            "           9.2106e-01,  1.2615e-01,  9.9201e-01,  3.9989e-02,  9.9920e-01,\n",
            "           1.2649e-02,  9.9992e-01,  4.0000e-03,  9.9999e-01,  1.2649e-03,\n",
            "           1.0000e+00],\n",
            "         [-9.5892e-01,  2.8366e-01,  9.9995e-01, -1.0342e-02,  4.7943e-01,\n",
            "           8.7758e-01,  1.5746e-01,  9.8753e-01,  4.9979e-02,  9.9875e-01,\n",
            "           1.5811e-02,  9.9988e-01,  5.0000e-03,  9.9999e-01,  1.5811e-03,\n",
            "           1.0000e+00],\n",
            "         [-2.7942e-01,  9.6017e-01,  9.4715e-01, -3.2080e-01,  5.6464e-01,\n",
            "           8.2534e-01,  1.8860e-01,  9.8205e-01,  5.9964e-02,  9.9820e-01,\n",
            "           1.8973e-02,  9.9982e-01,  6.0000e-03,  9.9998e-01,  1.8974e-03,\n",
            "           1.0000e+00],\n",
            "         [ 6.5699e-01,  7.5390e-01,  8.0042e-01, -5.9944e-01,  6.4422e-01,\n",
            "           7.6484e-01,  2.1956e-01,  9.7560e-01,  6.9943e-02,  9.9755e-01,\n",
            "           2.2134e-02,  9.9976e-01,  6.9999e-03,  9.9998e-01,  2.2136e-03,\n",
            "           1.0000e+00],\n",
            "         [ 9.8936e-01, -1.4550e-01,  5.7432e-01, -8.1863e-01,  7.1736e-01,\n",
            "           6.9671e-01,  2.5029e-01,  9.6817e-01,  7.9915e-02,  9.9680e-01,\n",
            "           2.5296e-02,  9.9968e-01,  7.9999e-03,  9.9997e-01,  2.5298e-03,\n",
            "           1.0000e+00],\n",
            "         [ 4.1212e-01, -9.1113e-01,  2.9126e-01, -9.5664e-01,  7.8333e-01,\n",
            "           6.2161e-01,  2.8078e-01,  9.5977e-01,  8.9879e-02,  9.9595e-01,\n",
            "           2.8457e-02,  9.9960e-01,  8.9999e-03,  9.9996e-01,  2.8460e-03,\n",
            "           1.0000e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 What is Self-Attention?\n",
        "In this section, we will explore Self-Attention and Multi-Head Attention mechanisms.\n",
        "\n",
        "Consider the sentence, \"The cat slept because it was tired.\" Here, \"it\" refers to \"the cat.\" While this is intuitive for humans, this may not be clear at all to a machine.\n",
        "\n",
        "Self-Attention allows the model to consider other positions in the input sequence while processing each word, enabling it to generate a vector that captures dependencies between words.\n",
        "\n",
        "Let's break down the self-attention mechanism step by step:\n",
        "\n",
        "1. **Input Projections:** For each word in the input, create three vectors: Query (Q), Key (K), and Value (V). Each vector has a dimension of 1x512.\n",
        "\n",
        "   In multi-head attention, we have multiple self-attention heads (e.g., 8 heads). Each head corresponds contains smaller vectors which are reshaped from the 1x512 vector.\n",
        "\n",
        "   **How to create Key, Query, and Value vectors?**\n",
        "\n",
        "   Use matrices (key, query, and value matrices) to generate these vectors. These matrices are learned during training.\n",
        "```\n",
        "Code Hint:\n",
        "If batch_size=32, sequence_length=10, and embedding_dimension=512, the output after embedding and positional encoding will be 32x10x512.\n",
        "First, project it to get K,Q,V matrices of shape 32x10x512. Next, create heads of shape 32x10x8x64. (8 is the number of heads in multi-head attention).\n",
        "```\n",
        "\n",
        "\n",
        "* **Step 2:** **Calculate Attention Scores:** Multiply the query matrix with the key matrix transpose: [Q x K.t]\n",
        "```\n",
        "Code Hint:\n",
        "If the dimensions of key, query, and value are 32x10x8x64, transpose them to 32x8x10x64.\n",
        "Then, multiply the query matrix with the key matrix transpose: (32x8x10x64) x (32x8x64x10) -> (32x8x10x10).\n",
        "```\n",
        "\n",
        "\n",
        "* **Step 3:**  **Scale Scores:** Divide the output matrix by the square root of the key matrix dimension and apply Softmax.\n",
        "```\n",
        "Code Hint:\n",
        "Divide the 32x8x10x10 vector by 8 (the square root of 64, the key matrix dimension).\n",
        "```\n",
        "\n",
        "\n",
        "* **Step 4:** **Weighted Sum:** Multiply the scores with the value matrix.\n",
        "```\n",
        "Code Hint:\n",
        "After step 3, the output will be 32x8x10x10. Multiply it with the value matrix (32x8x10x64) to get the output (32x8x10x64).\n",
        "```\n",
        "\n",
        "* **Step 5:** **Output Transformation:** Pass the result through a linear layer to form the final output of the multi-head attention.\n",
        "```\n",
        "Code Hint:\n",
        "Transpose the (32x8x10x64) vector to (32x10x8x64) and reshape it to (32x10x512).\n",
        "Then, pass it through a linear layer to get the output of (32x10x512).\n",
        "```\n",
        "\n",
        "\n",
        "Now that you have an overview of how multi-head attention works, let's implement it. You will gain a deeper understanding through the following code exercise.\n",
        "\n",
        "<hr>\n",
        "<h3>Task:</h3>\n",
        "Implement the `MultiHeadAttention` class. Complete the `__init__` and `forward` methods to perform the multi-head self-attention operation.\n",
        "\n",
        "```\n",
        "Code Hint:\n",
        "Ensure you properly reshape and transpose the tensors to match the required dimensions for matrix multiplication.\n",
        "```\n",
        "\n",
        "**Note:** Masking can be used in the decoder to prevent attending to future tokens, but more on this later\n"
      ],
      "metadata": {
        "id": "A30w9U9cqHQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, embed_dim=512, n_heads=8):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            embed_dim: dimension of embedding vector output\n",
        "            n_heads: number of self-attention heads\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.embed_dim = embed_dim    # 512 dim\n",
        "        self.n_heads = n_heads   # 8 heads\n",
        "        self.single_head_dim = embed_dim // n_heads   # 512 / 8 = 64, each key, query, and value head will be 64d\n",
        "\n",
        "        # TODO: Initialize key, query, value, and output projection matrices/layers.\n",
        "        # -- Note: Use biases only for the output projection layer. Not for the key, query, and value layers.\n",
        "        self.query_matrix = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.key_matrix = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.value_matrix = nn.Linear(embed_dim, embed_dim, bias=False)\n",
        "        self.output_projection = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, key, query, value, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            key: key vector\n",
        "            query: query vector\n",
        "            value: value vector\n",
        "            mask: mask for decoder\n",
        "\n",
        "        Returns:\n",
        "            output: vector from multi-head attention\n",
        "        \"\"\"\n",
        "        batch_size = key.size(0)\n",
        "\n",
        "        # TODO: Apply linear transformations for computing the key, query and value elements\n",
        "        query = self.query_matrix(query)\n",
        "        key = self.key_matrix(key)\n",
        "        value = self.value_matrix(value)\n",
        "\n",
        "        # TODO: Reshape key, query, and value\n",
        "        query = query.view(batch_size, -1, self.n_heads, self.single_head_dim).transpose(1, 2)\n",
        "        key = key.view(batch_size, -1, self.n_heads, self.single_head_dim).transpose(1, 2)\n",
        "        value = value.view(batch_size, -1, self.n_heads, self.single_head_dim).transpose(1, 2)\n",
        "\n",
        "\n",
        "        # TODO: Compute attention scores\n",
        "        attention_scores = torch.matmul(query, key.transpose(-2, -1))\n",
        "\n",
        "        # TODO: scale the dot products\n",
        "        scores = attention_scores / math.sqrt(self.single_head_dim)\n",
        "\n",
        "        # Apply masking, if mask in not None.\n",
        "        # Assume that product is the tensor with the scaled dot products\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-1e20'))\n",
        "\n",
        "        # TODO: Apply softmax\n",
        "        attention_weights = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # TODO: Compute weighted sum of value vectors and run it through the last layer\n",
        "        weighted_sum = torch.matmul(attention_weights, value)\n",
        "\n",
        "        weighted_sum = weighted_sum.transpose(1,2).contiguous().view(batch_size, -1, self.embed_dim)\n",
        "\n",
        "        output = self.output_projection(weighted_sum)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-20T09:58:01.918395Z",
          "iopub.execute_input": "2022-09-20T09:58:01.919235Z",
          "iopub.status.idle": "2022-09-20T09:58:01.936716Z",
          "shell.execute_reply.started": "2022-09-20T09:58:01.919181Z",
          "shell.execute_reply": "2022-09-20T09:58:01.935562Z"
        },
        "trusted": true,
        "id": "56YX739SqHQQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "mha = MultiHeadAttention(512, 8)\n",
        "mha.eval()\n",
        "with torch.no_grad():\n",
        "    key = torch.zeros(2, 10, 512)\n",
        "    query = torch.ones(2, 10, 512)\n",
        "    value = torch.zeros(2, 10, 512)\n",
        "    # Perform forward pass twice with the same inputs\n",
        "    output1 = mha(key, query, value)\n",
        "    print(mha.query_matrix.weight[0][:3])\n",
        "    print(output1[0][0][:3])"
      ],
      "metadata": {
        "id": "xkoBScJALp7v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca00471-376d-46b7-d203-35cbe9b21f75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0003,  0.0237, -0.0364], requires_grad=True)\n",
            "tensor([ 0.0141, -0.0128,  0.0270])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Decoder-only architecture\n",
        "\n",
        "In this section, we will fully implement the decoder-only architecture"
      ],
      "metadata": {
        "id": "60l2xNAWqReB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 4.1 Decoder Class\n",
        "\n",
        "<h2>Steps for the Decoder:</h2>\n",
        "\n",
        "**Step 1:**\n",
        "\n",
        "   The input (padded tokens of the sentence) is passed through the embedding layer and positional encoding layer.\n",
        "```\n",
        "Code Hint:\n",
        "If the input is of size 64 (batch size=32 and sequence length=64), after passing through the embedding layer, it becomes 32x10x512.\n",
        "This output is added to the corresponding positional encoding vector, producing a 32x10x512 output that is passed to the multi-head attention.\n",
        "```\n",
        "\n",
        "**Step 2:**\n",
        "  At each decoder block the processed input is passed through the multi-head attention layer to create a useful representational matrix.\n",
        "```\n",
        "Code Hint:\n",
        "The input to the multi-head attention is 32x10x512. Key, query, and value vectors are generated, ultimately producing a 32x10x512 output.\n",
        "```\n",
        "\n",
        "In the decoder the self-attention is masked. In other words, a causal mask is used with multi-head attention.\n",
        "\n",
        "**Why mask?**\n",
        "\n",
        "A mask is used to prevent a word from attending to future words in the sequence. For example, in the sentence \"I am a student,\" we do not want the word \"a\" to attend to the word \"student.\"\n",
        "```\n",
        "Code Hint:\n",
        "To create the attention mask, we use a triangular matrix with 1s and 0s. For example, a triangular matrix for a sequence length of 5 looks like this:\n",
        "\n",
        "1 0 0 0 0\n",
        "1 1 0 0 0\n",
        "1 1 1 0 0\n",
        "1 1 1 1 0\n",
        "1 1 1 1 1\n",
        "\n",
        "After the key is multiplied by the query, you should fill all zero positions with a very small number (e.g., -1e20) to avoid division errors.\n",
        "```\n",
        "\n",
        "**Step 3:**\n",
        "  The output from the multi-head attention is added to its input and then normalized.\n",
        "```\n",
        "Code Hint:\n",
        "The output from the multi-head attention (32x10x512) is added to the input (32x10x512) and then normalized.\n",
        "```\n",
        "  Before the residual connection and norm layers, the multi-head attention output should be forwared through a dropout layer.\n",
        "\n",
        "**Step 4:**\n",
        "  \n",
        "  The normalized output passes through a feed-forward layer and another normalization layer with a residual connection from the input of the feed-forward layer.\n",
        "```\n",
        "Code Hint:\n",
        "The normalized output (32x10x512) is passed through two linear layers: 32x10x512 -> 32x10x2048 -> 32x10x512.\n",
        "Finally, a residual connection is added, and the layer is normalized.\n",
        "This produces a 32x10x512 dimensional vector as the encoder's output.\n",
        "```\n",
        "Again, before the residual connection and norm layers, the feed-forward layer output should be forwared through a dropout layer.\n",
        "\n",
        "**Step 5:**\n",
        "\n",
        "Finally, we create a linear layer with a size equal to the vocabulary size of the target corpus. Do not use softmax after the linear layer. Before the final linear layer, there is another layer norm layer.\n",
        "\n",
        "<hr>\n",
        "<h3>Task:</h3>\n",
        "\n",
        "1. Implement the `__init__` and `forward` methods for `TransformerBlock`, making sure to apply masked attention with the given mask.\n",
        "2. Implement make_mask function in `TransformerDecoderOnly` to generate masks for the self-attention layers\n",
        "3. Implement the forward pass for `TransformerDecoderOnly`, including embedding, positional encoding, and the final linear layer with softmax. The `generate` function is provided as a helper function for inference / sampling\n"
      ],
      "metadata": {
        "id": "KzOxhFXtqHQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "           embed_dim: dimension of the embedding\n",
        "           expansion_factor: factor determining output dimension of the linear layer\n",
        "           n_heads: number of attention heads\n",
        "        \"\"\"\n",
        "        self.attention = MultiHeadAttention(embed_dim, n_heads)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_dim, expansion_factor * embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(expansion_factor * embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "           x: embeddings\n",
        "\n",
        "        Returns:\n",
        "           x_out: output of transformer block\n",
        "        \"\"\"\n",
        "\n",
        "        # TODO: Calculate attention output using masked self.\n",
        "        attention_output = self.attention(x, x, x, mask)\n",
        "\n",
        "        # TODO: Apply droppout on the attention outputs.\n",
        "        attention_output = self.dropout1(attention_output)\n",
        "\n",
        "        # TODO: Add residual connection and normalize\n",
        "        x = self.norm1(x + attention_output)\n",
        "\n",
        "        # TODO: Pass through feed forward layer\n",
        "        feed_forward_output = self.feed_forward(x)\n",
        "\n",
        "        # TODO: Apply dropout on the outputs of the feed forward layer\n",
        "        feed_forward_output = self.dropout2(feed_forward_output)\n",
        "\n",
        "        # TODO: Add residual connection and normalize\n",
        "        x_out = self.norm2(x + feed_forward_output)\n",
        "\n",
        "        return x_out\n",
        "\n",
        "\n",
        "class TransformerDecoderOnly(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, seq_len, num_layers=6, expansion_factor=4, n_heads=8):\n",
        "        super(TransformerDecoderOnly, self).__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "           vocab_size: vocabulary size of the target\n",
        "           embed_dim: dimension of embedding\n",
        "           seq_len: length of input sequence\n",
        "           num_layers: number of decoder layers\n",
        "           expansion_factor: factor determining the number of linear layers in the feed-forward layer\n",
        "           n_heads: number of heads in multi-head attention\n",
        "        \"\"\"\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.position_embedding = PositionalEmbedding(seq_len, embed_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList(\n",
        "            [TransformerBlock(embed_dim, expansion_factor=expansion_factor, n_heads=n_heads) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.norm_out = nn.LayerNorm(embed_dim)\n",
        "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def make_mask(self, seq):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            seq: sequence of indices. The shape should be [batch_size, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            mask: causal mask. The shape should be: [batch_size, 1, seq_len, seq_len]\n",
        "        \"\"\"\n",
        "        # TODO: Implement the mask for the sequence\n",
        "        batch_size, seq_len = seq.size()\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0).unsqueeze(1)\n",
        "        return mask.to(seq.device)\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: input vector with token\n",
        "\n",
        "        Returns:\n",
        "            out: output vector\n",
        "        \"\"\"\n",
        "        mask = self.make_mask(x)\n",
        "        mask = mask.to(x.device)\n",
        "\n",
        "        # TODO: Apply the embedding layer\n",
        "        x = self.word_embedding(x).to(x.device)\n",
        "\n",
        "        # TODO: Apply positional encoding\n",
        "        x = self.position_embedding(x)\n",
        "\n",
        "        # TODO: Pass through each decoder transformer block with mask\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        # TODO: Apply the final layer norm layer (self.norm_out)\n",
        "        x = self.norm_out(x)\n",
        "\n",
        "        # TODO: Apply final linear layer\n",
        "        out = self.fc_out(x)\n",
        "\n",
        "        return out\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-20T09:58:01.938748Z",
          "iopub.execute_input": "2022-09-20T09:58:01.939031Z",
          "iopub.status.idle": "2022-09-20T09:58:01.954321Z",
          "shell.execute_reply.started": "2022-09-20T09:58:01.938997Z",
          "shell.execute_reply": "2022-09-20T09:58:01.953342Z"
        },
        "trusted": true,
        "id": "tCTs1mjWqHQR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Test the coded transformer blocks:</h3>"
      ],
      "metadata": {
        "id": "lUU2tFtIoqkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_transformer_block():\n",
        "    embed_dim = 512\n",
        "    n_heads = 8\n",
        "    expansion_factor = 4\n",
        "\n",
        "    # Define input shapes: batch_size x seq_length x embed_dim\n",
        "    batch_size = 32\n",
        "    seq_length = 4\n",
        "\n",
        "    # Create random input tensor\n",
        "    x = torch.rand(batch_size, seq_length, embed_dim)\n",
        "\n",
        "    # Create the TransformerBlock\n",
        "    transformer_block = TransformerBlock(embed_dim, expansion_factor, n_heads)\n",
        "\n",
        "    # Pass the inputs through the transformer block\n",
        "    output = transformer_block(x)\n",
        "\n",
        "    # Check the output shape: should be [batch_size, seq_length, embed_dim]\n",
        "    assert output.shape == (batch_size, seq_length, embed_dim), \\\n",
        "        f\"Expected output shape {(batch_size, seq_length, embed_dim)}, but got {output.shape}\"\n",
        "\n",
        "    print(\"TransformerBlock test passed!\")\n",
        "\n",
        "test_transformer_block()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_ObiBETirny",
        "outputId": "9194a51d-68be-490e-a5de-746a559f537f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerBlock test passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.testing import assert_close\n",
        "\n",
        "batch_size = 32\n",
        "seq_len = 10\n",
        "embed_dim = 512\n",
        "vocab_size = 10000\n",
        "n_heads = 8\n",
        "num_layers = 2\n",
        "expansion_factor = 4\n",
        "\n",
        "# Test case 1: Full Transformer Decoder functionality\n",
        "def test_transformer_decoder_full_pass():\n",
        "    \"\"\"\n",
        "    Tests the forward pass of TransformerDecoderOnly and check if output has expected shape and behavior.\n",
        "    \"\"\"\n",
        "    # Initialize a TransformerDecoder\n",
        "    decoder = TransformerDecoderOnly(\n",
        "        vocab_size=vocab_size,\n",
        "        embed_dim=embed_dim,\n",
        "        seq_len=seq_len,\n",
        "        num_layers=num_layers,\n",
        "        expansion_factor=expansion_factor,\n",
        "        n_heads=n_heads\n",
        "    )\n",
        "\n",
        "    x = torch.randint(0, vocab_size, (batch_size, seq_len))\n",
        "\n",
        "    # Forward pass through the transformer decoder\n",
        "    output = decoder(x)\n",
        "\n",
        "    # Assert the output has the correct shape (batch_size, seq_len, vocab_size)\n",
        "    assert output.shape == (batch_size, seq_len, vocab_size), \\\n",
        "        f\"Expected {(batch_size, seq_len, vocab_size)}, but got {output.shape}\"\n",
        "    output = F.softmax(output, dim=-1)\n",
        "    # Check that the output is a valid probability distribution (i.e., each row sums to 1 after softmax)\n",
        "    assert_close(output.sum(dim=-1), torch.ones(batch_size, seq_len), rtol=1e-2, atol=1e-2)\n",
        "\n",
        "    print(\"TransformerDecoderOnly passed the full forward pass test!\")\n",
        "\n",
        "\n",
        "test_transformer_decoder_full_pass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn8h72e7jPV_",
        "outputId": "34be6d63-d36d-4568-e38f-a7a083280ab9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max_seq_len: 10\n",
            "TransformerDecoderOnly passed the full forward pass test!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Train and test our Decoder-only architecture\n",
        "\n",
        "Now, we're going to the train the modle on the TinyStories dataset with the GPT-2 tokenizer. The goal is to try to learn a small language model that can generate creative and coherent text in English."
      ],
      "metadata": {
        "id": "vCplptw3qHQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install some dependencies"
      ],
      "metadata": {
        "id": "joiEZbfJr0ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets tiktoken"
      ],
      "metadata": {
        "id": "rXLQRkKfr4zQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb3040a-377b-49c7-cf91-d876ad643f81"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, tiktoken, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 tiktoken-0.8.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Model hyperparameters\n",
        "Now we are going to, define the model hyperparameters\n",
        "\n",
        "No code is needed here."
      ],
      "metadata": {
        "id": "AktLI-6Frluo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "# Model  hyperparameters\n",
        "batch_size = 128  # how many independent sequences will we process in parallel?\n",
        "model_max_seq_len = block_size = 64  # what is the maximum context length for predictions.\n",
        "max_iters = 5000  # 5000\n",
        "eval_interval = 500 # 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 100\n",
        "n_embd = 512\n",
        "n_head = 8\n",
        "n_layer = 6 # 12\n",
        "dropout = 0.1\n",
        "\n",
        "# Loading the tiktoken tokenizer used in GPT2\n",
        "enc = tiktoken.get_encoding(\"gpt2\")  # tokenizer - GPT2\n",
        "vocab_size = enc.n_vocab\n",
        "# ------------"
      ],
      "metadata": {
        "id": "ReUzqDS8rf2o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Building dataset and dataloader\n",
        "\n",
        "Now we are going to download the dataset (TinyStories dataset), tokenize it using the tiktoken tokenizer from GPT-2, divide it to train and test splits.\n",
        "\n",
        "No code is needed here"
      ],
      "metadata": {
        "id": "UQRAxxnwrCAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('roneneldan/TinyStories')\n",
        "# loading first 12000 stories from the dataset\n",
        "text = '\\n'.join(dataset['train']['text'][:12000])\n",
        "\n",
        "print(\"Print the first 1000 characters from the TinyStories:\")\n",
        "print(text[:1000])\n",
        "\n",
        "# Tokenize the data:\n",
        "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
        "print(\"\\n\\n\\n\")\n",
        "print(\"Data after the the tokenization process (fist 100 indices):\")\n",
        "print(data[:100])\n",
        "\n",
        "# Make the train and test splits\n",
        "n = int(0.9*len(data))  # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "print(f\"Train data shape {train_data.shape}, validation data shape {val_data.shape}\")\n",
        "# data loading\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "HlyKbGlRp9UK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796,
          "referenced_widgets": [
            "674e1a2190404332bb66e1c8000b88a9",
            "fb4eedcec5a94189b8f7c5a1d1d954b2",
            "f93eec4ec41b469587108360446ae8a2",
            "fd55ca24d7364a3d9ab4cdc12cf157e4",
            "2658dba4803740889cf89fc423f5050e",
            "d963bbf55022475295a0663fa781eaa7",
            "84784358c0ff4965a7b0b8ba530ebc52",
            "1b9f6255e9b849498e4598399899f01e",
            "bd62641b7d6541b0add7741b742e4105",
            "aac6397929d14b80971ab09eff52cd08",
            "6088a18a8c8e4bbd8fdaa0f922658526",
            "6e418e240318491a8be58598ba9f2986",
            "7df7ffbc29714d4d8e28f89d52844c8c",
            "75d49d1816d64e23934131989bd7f9ed",
            "577b165d0d3d49e6b56883cf490bdbba",
            "2eb35e602d3b40a791ca1b1285b7f802",
            "fe2eed82a79c48afa8d4972bd26d82d5",
            "33244d60841f4ac58707759117ff0450",
            "b3f1838c11204d5bb11a516a2356a25c",
            "9435a59d307942f29084292695e246e8",
            "70eea11972fc4432b02e19f157f70a9a",
            "4400ca0e9c4b408e9e8c9dcc35d1f932",
            "ab0d6dca72304ec58387698586aab54d",
            "49dc69cc312c4146aabf049fb3c15c9c",
            "caae2e9517b04fa7adfdb50c9f209271",
            "e9af8d6f73854ca1a65b22505870d0c5",
            "88882eeab19442e69e0a7d280992369c",
            "77660fb83f344710aa0080351eaef0f3",
            "bd68853fe6cd49028968f2fc14fa80b3",
            "952de0c226ea455d921eedbfa30fdfb7",
            "e3fa807af904422c82f158ccc58eed22",
            "67f05cf36c6a4a6d8314c9588544184b",
            "0288c67205fb4fcc9e705351c818b3cf",
            "42fb9f59cfc44b58898dcc611b3d1732",
            "dba3a2d56c5340c08aad3b65288871cd",
            "64680949efb04462978cd2e7ee588fc8",
            "0e6d0a7073144a319a5f55ed460ef26b",
            "3f0ea25502bd46c3b9d08670437af379",
            "6a5a7697a86740eaa608765380a818ea",
            "eb3c4ede4a1d450b8e7167ae610da4fb",
            "33bf1175f4d2497aa8128bf54edc4421",
            "f22267bf265644b5ad94112fba555e5c",
            "c2b79cecccbf4af49e808b3939b1001f",
            "cd2b1e70e903465cbb03681af1df2848",
            "5976942dae8b42b9b18009e7c9645d24",
            "7106c3a4ff8d435e8db5413f5fe7afc5",
            "47fa711b2edd43bebf221ddd9cd892f9",
            "471c42b5b5d8408780a1853f2ecf9a39",
            "127a027a79f6446d8eb4cfc2921ba049",
            "d96adaacdaca4567b0ceab8493b3fb5b",
            "e633eaa08a1c416d8ced3562c3a58000",
            "6514ae7c1b1647a2aafb7a687bf20bda",
            "21e7fcb0f5dd4e5c9a4c4b5edb608232",
            "2b1dfd27366f4794b8ef4653cbdcf115",
            "788d1485dd0040c79ac28eb3b9e5df24",
            "77ba244a05ea44bda3d6421701b7f324",
            "9c39e58d6d3c42709b16b12b918b8c48",
            "08175fab5a744f38965029d445e965ad",
            "e846e384ab9e4068ba6281254997ccaa",
            "c7c97c88b9e74e4c9500eea796fec8ac",
            "e0c1b54611ba424ea7cecbe10ad18aec",
            "7760ecb175a44ecb94b73b1886ba956b",
            "77ca02a43dd145a5b957572221d68d77",
            "9968eb3a10a94c589069da585a4c30a8",
            "aa016628ce1642e3b2fac20ecd21fb61",
            "3b437a10911f4d0dac819d740b2b705f",
            "9afe22b4e97a4db385b95dde83901efd",
            "6ef29e0e250547278ade74a7ed1a0282",
            "c321a8aa081c4fe0af8c295bfdfeaf39",
            "1bf4c09b4c914508ac0c68c00a6eb72e",
            "9e291f7017274c57ad0bf7248ae67ab2",
            "31e5c68e28eb4a7dae8d30e299fab4c4",
            "d4ef9c6eed814f5fa2f6af28f111df52",
            "6361063949014595949c9817b7eb9170",
            "924b8fe1e94c452a8dc65f4962ea2bed",
            "fdfe897cda5f4722b364efe7dee68999",
            "6b1139c1bd58491a9629ef3529da1bd8",
            "567d5d0103aa4b3cbb36ba6d06517eaa",
            "bd56968658004449a8fa7c331646142e",
            "4ab48db2aba74d3abb636661110727c7",
            "d270e031b68747fbad6afe4770021653",
            "3eda89e8f6784a8a97647941a5343e26",
            "ce9fa4607012457396a246c8f4571f44",
            "60201c68f3eb4998957fcffec3d06385",
            "a04f0be84e2b45aab4f20a05cc4c7b91",
            "2c4b083a4ba4412089799d70797d4576",
            "1091ac7ff713420c9e21a1c1f01b5d0a",
            "e132eb7bca4f461daf6963d86f06af58"
          ]
        },
        "outputId": "710029b0-33f1-4e9c-fb58-f90d22f0f042"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/1.06k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "674e1a2190404332bb66e1c8000b88a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00004-2d5a1467fff1081b.parquet:   0%|          | 0.00/249M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e418e240318491a8be58598ba9f2986"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00001-of-00004-5852b56a2bd28fd9.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab0d6dca72304ec58387698586aab54d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00002-of-00004-a26307300439e943.parquet:   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42fb9f59cfc44b58898dcc611b3d1732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00003-of-00004-d243063613e5a057.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5976942dae8b42b9b18009e7c9645d24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(…)-00000-of-00001-869c898b519ad725.parquet:   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77ba244a05ea44bda3d6421701b7f324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9afe22b4e97a4db385b95dde83901efd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "567d5d0103aa4b3cbb36ba6d06517eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Print the first 1000 characters from the TinyStories:\n",
            "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
            "\n",
            "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
            "\n",
            "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.\n",
            "Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\n",
            "\n",
            "One day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. B\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Data after the the tokenization process (fist 100 indices):\n",
            "tensor([ 3198,  1110,    11,   257,  1310,  2576,  3706, 20037,  1043,   257,\n",
            "        17598,   287,   607,  2119,    13,  1375,  2993,   340,   373,  2408,\n",
            "          284,   711,   351,   340,   780,   340,   373,  7786,    13, 20037,\n",
            "         2227,   284,  2648,   262, 17598,   351,   607,  1995,    11,   523,\n",
            "          673,   714, 34249,   257,  4936,   319,   607, 10147,    13,   198,\n",
            "          198,    43,   813,  1816,   284,   607,  1995,   290,   531,    11,\n",
            "          366, 29252,    11,   314,  1043,   428, 17598,    13,  1680,   345,\n",
            "         2648,   340,   351,   502,   290, 34249,   616, 10147,  1701,  2332,\n",
            "         1995, 13541,   290,   531,    11,   366,  5297,    11, 20037,    11,\n",
            "          356,   460,  2648,   262, 17598,   290,  4259,   534, 10147,   526])\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Train data shape torch.Size([2352219]), validation data shape torch.Size([261358])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Create GPT Model And Its Optimizer\n",
        "\n",
        "Your tasks are:\n",
        "1. Define / create the decoder only model using the hyperparameters set above\n",
        "2. Define an AdamW optimizer using the learning rate (hyperparameter set above)\n",
        "3. Print from model the following stuff:\n",
        "  - The number of trainable parameters in the input embedding layer\n",
        "  - The number of trainable parameters in all the transformer blocks\n",
        "  - The number of trainable parameters in the final linear layer of the model\n",
        "  - The total number of trainable parameters."
      ],
      "metadata": {
        "id": "60Vo8V3UubGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Define / create the model (Accut)\n",
        "model = TransformerDecoderOnly(vocab_size, n_embd, model_max_seq_len, num_layers=n_layer, expansion_factor=4, n_heads=n_head)\n",
        "\n",
        "# print(model)\n",
        "print(model)\n",
        "\n",
        "# Set the model to the device using, e.g., m = model.to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "# TODO create a AdamW optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# TODO print the asked number of trainable parameters\n",
        "# Counting function\n",
        "def count_parameters(module):\n",
        "    return sum(p.numel() for p in module.parameters() if p.requires_grad)\n",
        "\n",
        "# The number of trainable parameters in the input embedding layer\n",
        "input_embedding_params = count_parameters(model.word_embedding)\n",
        "# The number of trainable parameters in all the transformer blocks\n",
        "transformer_blocks_params = count_parameters(model.layers)\n",
        "# The number of trainable parameters in the final linear layer of the model\n",
        "final_linear_layer_params = count_parameters(model.fc_out)\n",
        "# The total number of trainable parameters\n",
        "total_params = count_parameters(model)\n",
        "\n",
        "# Print the trainable parameters\n",
        "print(f\"The number of trainable parameters in the input embedding layer: {input_embedding_params}\")\n",
        "print(f\"The number of trainable parameters in all the transformer blocks: {transformer_blocks_params}\")\n",
        "print(f\"The number of trainable parameters in the final linear layer of the model: {final_linear_layer_params}\")\n",
        "print(f\"The total number of trainable parameters: {total_params}\")"
      ],
      "metadata": {
        "id": "XFaCK7VTuXSj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bfc743-fa85-4036-e3a0-2b9ddfe636e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max_seq_len: 64\n",
            "TransformerDecoderOnly(\n",
            "  (word_embedding): Embedding(50257, 512)\n",
            "  (position_embedding): PositionalEmbedding()\n",
            "  (layers): ModuleList(\n",
            "    (0-5): 6 x TransformerBlock(\n",
            "      (attention): MultiHeadAttention(\n",
            "        (query_matrix): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (key_matrix): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (value_matrix): Linear(in_features=512, out_features=512, bias=False)\n",
            "        (output_projection): Linear(in_features=512, out_features=512, bias=True)\n",
            "      )\n",
            "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (feed_forward): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (1): ReLU()\n",
            "        (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "      )\n",
            "      (dropout1): Dropout(p=0.2, inplace=False)\n",
            "      (dropout2): Dropout(p=0.2, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (norm_out): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (fc_out): Linear(in_features=512, out_features=50257, bias=True)\n",
            ")\n",
            "The number of trainable parameters in the input embedding layer: 25731584\n",
            "The number of trainable parameters in all the transformer blocks: 18905088\n",
            "The number of trainable parameters in the final linear layer of the model: 25781841\n",
            "The total number of trainable parameters: 70419537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Define the Loss Function"
      ],
      "metadata": {
        "id": "BUh4HKNVyrC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(logits, targets):\n",
        "    \"\"\"\n",
        "      Args:\n",
        "          logits: predicted logits (pre-softmax activations) from the model. Shape: [batch_size, seq_len, vocab_size]\n",
        "          targets: target vocabulary indices. Shape [batch_size, seq_len]\n",
        "\n",
        "      Returns:\n",
        "          loss: scalar value with the average cross-entropy loss\n",
        "    \"\"\"\n",
        "    # TODO implement the cross_entropy loss\n",
        "    loss_f = nn.CrossEntropyLoss()\n",
        "    loss = loss_f(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "2-khxr48ypjo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Train the GPT Model And Its Optimizer\n",
        "\n",
        "Your tasks are to write the training and evaluation code that does the following things:\n",
        "1. Train the model for `max_iters` using the training set.\n",
        "2. Every `eval_interval` eveluates the model (computes the loss) on both the test set and the train set, using `eval_iters` iterations for each split. Report the average loss on the train and test set from this."
      ],
      "metadata": {
        "id": "Pwi9NGxpwwHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "\n",
        "# Cosine Annealing LR Scheduler (for tuning the learning rate)\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=max_iters, eta_min=1e-5)\n",
        "\n",
        "early_stopping_threshold = 5  # Stop training if no improvement in val loss for 5 evaluations\n",
        "best_val_loss = float('inf')\n",
        "no_improvement = 0\n",
        "\n",
        "model.train()\n",
        "for iter in tqdm(range(max_iters)):\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        model.eval()\n",
        "        losses = {'train': 0, 'val': 0,}\n",
        "        for split in ['train', 'val']:\n",
        "            total_loss = 0\n",
        "            for k in range(eval_iters):\n",
        "              X, Y = get_batch(split)\n",
        "              # TODO: fill the code. It must compute the average loss on the 'train' or 'val' split using eval_iters\n",
        "              X, Y = X.to(device), Y.to(device)\n",
        "\n",
        "              logits = model(X)\n",
        "              loss = loss_function(logits, Y)\n",
        "              total_loss += loss.item()\n",
        "            # Compute the average loss over eval_iters\n",
        "            losses[split] = total_loss / eval_iters\n",
        "        # for each.\n",
        "        scheduler.step(losses['val'])\n",
        "\n",
        "        # Check for early stopping\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            no_improvement = 0\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "        # Stop training if no improvement in val loss for early_stopping_threshold evaluations\n",
        "        if no_improvement >= early_stopping_threshold:\n",
        "            print(f\"Stopping early at iteration {iter}, best validation loss: {best_val_loss:.4f}\")\n",
        "            break\n",
        "\n",
        "        model.train()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "    xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "    # TODO: implement a training iteration (forward, loss computation, backward, optimizer step, etc).\n",
        "    # Forward pass: compute logits\n",
        "    logits = model(xb)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = loss_function(logits, yb)\n",
        "\n",
        "    # Backward pass: compute gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient update\n",
        "    optimizer.step()\n",
        "\n",
        "    # evaluate the loss"
      ],
      "metadata": {
        "id": "jLs0ghmfwpgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9e5dce-901f-46a7-97b8-125e1efc2e14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 11.0375, val loss 11.0335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 502/5000 [01:38<2:58:27,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 500: train loss 2.9695, val loss 3.0569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1002/5000 [03:04<2:38:57,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1000: train loss 2.5653, val loss 2.7616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 1502/5000 [04:31<2:18:04,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1500: train loss 2.3334, val loss 2.6233\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2002/5000 [05:57<1:58:41,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2000: train loss 2.1637, val loss 2.5527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 2502/5000 [07:23<1:38:52,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 2500: train loss 2.0143, val loss 2.5310\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 3002/5000 [08:50<1:19:19,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 3000: train loss 1.8986, val loss 2.5216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 3502/5000 [10:17<59:30,  2.38s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 3500: train loss 1.7835, val loss 2.5251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 4002/5000 [11:43<39:25,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 4000: train loss 1.6933, val loss 2.5465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 4502/5000 [13:10<19:45,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 4500: train loss 1.6029, val loss 2.5688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [14:36<00:00,  5.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 4999: train loss 1.5247, val loss 2.6006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To achieve good results (low validation loss), you will probably need to play (tune) the `learning_rate` and max training duration (`max_iters`)."
      ],
      "metadata": {
        "id": "ZoFnxodVC6ZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Generate stories using the trained model.\n",
        "\n",
        "No code is needed here"
      ],
      "metadata": {
        "id": "0VjJ_bfUDlp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate from the model\n",
        "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "context = torch.tensor(enc.encode('\\n'), dtype=torch.long, device=device).unsqueeze(0)\n",
        "print(enc.decode(model.generate(context, max_new_tokens=200)[0].tolist()))"
      ],
      "metadata": {
        "id": "Q_jd49OD1gIg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b074e05a-6b3d-4d57-e4a8-a9be788ab512"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "And so, one day, the fairy waved her wand and waved her wand. The fairy felt very proud of herself for becoming a hero!\n",
            "\n",
            "The fairy smiled and twirled around with pride, stars jumped out together. With the chirp, the fairy would remind her of all the wonderful gift of his magical life!\n",
            "Once upon a time, there was a swimming in the water. It was so beautiful that it almost fell from the ocean. The family took it home and together they carried it outside. Soon, they were so happy that it was back to shore. \n",
            "\n",
            "The happy sea knew it was time for a dive to sail. The seagull was happy that he got to please and skillfully. He was a loyal friend because he could say they got care.\n",
            "\n",
            "Later that day, the seahorse played catch their own water in the bathtub. The fish had a big stick that touched the wipe to snuck and bubbles with all the colors\n"
          ]
        }
      ]
    }
  ]
}